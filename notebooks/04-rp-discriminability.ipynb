{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.discriminability import discr_stat\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_key = 'latent'\n",
    "## Define paths\n",
    "basedir = Path('..')\n",
    "datadir = basedir / 'data'\n",
    "rawdir = datadir / 'raw'\n",
    "gccadir = datadir / 'interim' / 'gcca250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path,\n",
    "              level='(e|n)',\n",
    "              subject='([0-9]{3})',\n",
    "              task='(.+?)',\n",
    "              filetype='h5',\n",
    "              flag=''):\n",
    "    files = []\n",
    "    query = f'^{level}_sub-'\n",
    "    query += f'{subject}_ses-1_'\n",
    "    query += f'task-{task}{flag}\\.{filetype}'\n",
    "    for f in os.listdir(path):\n",
    "        match = re.search(query, f)\n",
    "        if match:\n",
    "            files.append((f, match.groups()))\n",
    "    \n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['restingstate', 'openmonitoring', 'compassion']\n",
    "levels = ['e', 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 75.11it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 81.78it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 96.69it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 80.52it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 77.78it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 68.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## Get filenames for each task, novice vs. experienced\n",
    "## Load a single set of latents\n",
    "\n",
    "#latents_inter = {l:{t:[] for t in tasks} for l in levels}\n",
    "#labels_inter = {l:{t:[] for t in tasks} for l in levels}\n",
    "\n",
    "#latents_intra = {t:{l:[] for l in levels} for t in tasks}\n",
    "#labels_intra = {t:{l:[] for l in levels} for t in tasks}\n",
    "\n",
    "latents = []; labels_lt = []; labels_l = []; labels_t = []\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "for level in levels:\n",
    "    for task in tasks:\n",
    "        paths = get_files(path=gccadir, level=level, task=task, flag='_gcca')\n",
    "        \n",
    "        n_load = len(paths)\n",
    "\n",
    "        for path,subj in tqdm(paths[:n_load]):\n",
    "            h5f = h5py.File(gccadir / path,'r')\n",
    "            latent = h5f[h5_key][:][:,:n_components]\n",
    "            h5f.close()\n",
    "            \n",
    "            latents.append(latent)\n",
    "            labels_lt.append(f'{level}_{task}')\n",
    "            labels_l.append(level)\n",
    "            labels_t.append(task)\n",
    "            \n",
    "\n",
    "labels_lt = np.array(labels_lt)\n",
    "labels_t = np.array(labels_t)\n",
    "labels_l = np.array(labels_l)\n",
    "latents = np.array(latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Distance Matrices for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancedir = datadir / 'interim' / 'gcca_distances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(X, metric):\n",
    "    if metric == 'euclidean':\n",
    "        return(euclidean_distances(X.reshape(X.shape[0], -1)))\n",
    "    elif metric == 'spectral':\n",
    "        dm = np.zeros((X.shape[0], X.shape[0]))\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(i+1, X.shape[0]):\n",
    "                temp = X[i] - X[j]\n",
    "                _,s,_ = svds(np.array(X[i] - X[j], dtype=float), k=1)\n",
    "                dm[i,j] = s[0]; dm[j,i] = s[0]\n",
    "        return(dm)\n",
    "    elif metric == 'pairwise':\n",
    "        pass\n",
    "                 \n",
    "def get_save_classes(labels, level1='',task1='',level2='',task2='',task3='',metric='euclidean'):\n",
    "    global latents\n",
    "    ## Create search keys and get indices\n",
    "    key1 = f'{level1}_{task1}'\n",
    "    key2 = f'{level2}_{task2}'\n",
    "    idx1 = [i for i,label in enumerate(labels) if key1 in label]\n",
    "    idx2 = [i for i,label in enumerate(labels) if key2 in label]\n",
    "    print(f'Len of {key1}: {len(idx1)}')\n",
    "    print(f'Len of {key2}: {len(idx2)}')\n",
    "    if not task3 == '':\n",
    "        key3 = f'_{task3}'\n",
    "        idx3 = [i for i,label in enumerate(labels) if key3 in label]\n",
    "        print(f'Len of {key3}: {len(idx3)}')\n",
    "        idxs = np.hstack((idx1, idx2, idx3))\n",
    "        \n",
    "        ## Get relevant stuff\n",
    "        distances = get_distance_matrix(latents[idxs], metric=metric)\n",
    "        labels2 = np.hstack((['1'] * len(idx1), ['2'] * len(idx2), ['3'] * len(idx3)))\n",
    "\n",
    "        ## Save relevant stuff\n",
    "        pd.DataFrame(distances).to_csv(distancedir / f'{key1}_{key2}_{key3}_distances.csv', header=False, index=False)\n",
    "        pd.DataFrame(labels2).to_csv(distancedir / f'{key1}_{key2}_{key3}_labels.csv', header=False, index=False)\n",
    "    else:\n",
    "        idxs = np.hstack((idx1, idx2))\n",
    "    \n",
    "        ## Get relevant stuff\n",
    "        distances = distances = get_distance_matrix(latents[idxs], metric=metric)\n",
    "        labels2 = np.hstack((['1'] * len(idx1), ['2'] * len(idx2)))\n",
    "\n",
    "        ## Save relevant stuff\n",
    "        pd.DataFrame(distances).to_csv(distancedir / f'{key1}_{key2}_distances.csv', header=False, index=False)\n",
    "        pd.DataFrame(labels2).to_csv(distancedir / f'{key1}_{key2}_labels.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_metric = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of e_restingstate: 29\n",
      "Len of n_restingstate: 47\n",
      "Len of e_openmonitoring: 29\n",
      "Len of n_openmonitoring: 47\n",
      "Len of e_compassion: 29\n",
      "Len of n_compassion: 47\n"
     ]
    }
   ],
   "source": [
    "## Inter t (3)\n",
    "for task in tasks:\n",
    "    get_save_classes(labels=labels_lt, level1=levels[0], level2=levels[1], task1=task, task2=task, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of e_restingstate: 29\n",
      "Len of e_openmonitoring: 29\n",
      "Len of e_restingstate: 29\n",
      "Len of e_compassion: 29\n",
      "Len of e_openmonitoring: 29\n",
      "Len of e_compassion: 29\n",
      "Len of n_restingstate: 47\n",
      "Len of n_openmonitoring: 47\n",
      "Len of n_restingstate: 47\n",
      "Len of n_compassion: 47\n",
      "Len of n_openmonitoring: 47\n",
      "Len of n_compassion: 47\n"
     ]
    }
   ],
   "source": [
    "## Inter experience (2)\n",
    "for level in levels:\n",
    "    for t1,t2 in combinations(tasks, 2):\n",
    "        get_save_classes(labels=labels_lt, level1=level, level2=level, task1=t1, task2=t2, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of e_restingstate: 29\n",
      "Len of n_openmonitoring: 47\n",
      "Len of e_openmonitoring: 29\n",
      "Len of n_restingstate: 47\n",
      "Len of e_restingstate: 29\n",
      "Len of n_compassion: 47\n",
      "Len of e_compassion: 29\n",
      "Len of n_restingstate: 47\n",
      "Len of e_openmonitoring: 29\n",
      "Len of n_compassion: 47\n",
      "Len of e_compassion: 29\n",
      "Len of n_openmonitoring: 47\n"
     ]
    }
   ],
   "source": [
    "## Pairwise (9)\n",
    "## Inter experience (2)\n",
    "for t1,t2 in combinations(tasks, 2):\n",
    "    get_save_classes(labels=labels_lt, level1=levels[0], level2=levels[1], task1=t1, task2=t2, metric=distance_metric)\n",
    "    get_save_classes(labels=labels_lt, level1=levels[0], level2=levels[1], task1=t2, task2=t1, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of e_: 87\n",
      "Len of n_: 141\n"
     ]
    }
   ],
   "source": [
    "## Novice vs. Expert (9)\n",
    "get_save_classes(labels=labels_lt, level1=levels[0], level2=levels[1], metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of _restingstate: 76\n",
      "Len of _openmonitoring: 76\n",
      "Len of _restingstate: 76\n",
      "Len of _compassion: 76\n",
      "Len of _openmonitoring: 76\n",
      "Len of _compassion: 76\n"
     ]
    }
   ],
   "source": [
    "## Inter-trait (3)\n",
    "for t1,t2 in combinations(tasks, 2):\n",
    "    get_save_classes(labels=labels_lt, task1=t1, task2=t2, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of _restingstate: 76\n",
      "Len of _openmonitoring: 76\n",
      "Len of _compassion: 76\n"
     ]
    }
   ],
   "source": [
    "## Triplet inter-trait (1)\n",
    "get_save_classes(labels=labels_lt, task1=tasks[0], task2=tasks[1], task3=tasks[2], metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 139.16it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 255.50it/s]\n"
     ]
    }
   ],
   "source": [
    "## Experts meditation vs not\n",
    "paths1 = get_files(path=gccadir, level='e', task=f'({tasks[1]}|{tasks[2]})', flag='_gcca')\n",
    "paths2 = get_files(path=gccadir, level='e', task=tasks[0], flag='_gcca')\n",
    "\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "for path,_ in tqdm(paths1):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('1')\n",
    "    \n",
    "for path,_ in tqdm(paths2):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('2')\n",
    "    \n",
    "distances = get_distance_matrix(np.array(latents), metric=distance_metric)\n",
    "\n",
    "## Save relevant stuff\n",
    "pd.DataFrame(distances).to_csv(distancedir / f'e_meditating_e_resting_distances.csv', header=False, index=False)\n",
    "pd.DataFrame(labels).to_csv(distancedir / f'e_meditating_e_resting_labels.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 405.69it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 473.35it/s]\n"
     ]
    }
   ],
   "source": [
    "## Novices meditation vs not\n",
    "paths1 = get_files(path=gccadir, level='n', task=f'({tasks[1]}|{tasks[2]})', flag='_gcca')\n",
    "paths2 = get_files(path=gccadir, level='n', task=tasks[0], flag='_gcca')\n",
    "\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "for path,_ in tqdm(paths1):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('1')\n",
    "    \n",
    "for path,_ in tqdm(paths2):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('2')\n",
    "    \n",
    "distances = get_distance_matrix(np.array(latents), metric=distance_metric)\n",
    "\n",
    "## Save relevant stuff\n",
    "pd.DataFrame(distances).to_csv(distancedir / f'n_meditating_n_resting_distances.csv', header=False, index=False)\n",
    "pd.DataFrame(labels).to_csv(distancedir / f'n_meditating_n_resting_labels.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 377.63it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 310.51it/s]\n"
     ]
    }
   ],
   "source": [
    "## Experts meditating vs novices not\n",
    "paths1 = get_files(path=gccadir, level='e', task=f'({tasks[1]}|{tasks[2]})', flag='_gcca')\n",
    "paths2 = get_files(path=gccadir, level='n', task=tasks[0], flag='_gcca')\n",
    "\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "for path,_ in tqdm(paths1):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('1')\n",
    "    \n",
    "for path,_ in tqdm(paths2):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('2')\n",
    "    \n",
    "distances = get_distance_matrix(np.array(latents), metric=distance_metric)\n",
    "\n",
    "## Save relevant stuff\n",
    "pd.DataFrame(distances).to_csv(distancedir / f'e_meditating_n_resting_distances.csv', header=False, index=False)\n",
    "pd.DataFrame(labels).to_csv(distancedir / f'e_meditating_n_resting_labels.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:02<00:00, 64.78it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 64.31it/s]\n"
     ]
    }
   ],
   "source": [
    "## All meditating vs all not\n",
    "paths1 = get_files(path=gccadir, level='(e|n)', task=f'({tasks[1]}|{tasks[2]})', flag='_gcca')\n",
    "paths2 = get_files(path=gccadir, level='(e|n)', task=tasks[0], flag='_gcca')\n",
    "\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "for path,_ in tqdm(paths1):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('1')\n",
    "    \n",
    "for path,_ in tqdm(paths2):\n",
    "    h5f = h5py.File(gccadir / path,'r')\n",
    "    latent = h5f[h5_key][:][:,:n_components]\n",
    "    h5f.close()\n",
    "    latents.append(latent)\n",
    "    labels.append('2')\n",
    "    \n",
    "distances = get_distance_matrix(np.array(latents), metric=distance_metric)\n",
    "\n",
    "## Save relevant stuff\n",
    "pd.DataFrame(distances).to_csv(distancedir / f'_meditating__resting_distances.csv', header=False, index=False)\n",
    "pd.DataFrame(labels).to_csv(distancedir / f'_meditating__resting_labels.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda19db8c3c14cd47c29dff39736515a2a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
